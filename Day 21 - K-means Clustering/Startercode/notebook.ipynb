{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-74934e039aa71a2d",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# Day 21 notebook\n",
                "The objectives of this notebook are to practice\n",
                "\n",
                "* The K-means algorithm\n",
                "* Selecting the number of clusters (K)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-ec05e9ac95957bd0",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Modules for this activity"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-35cd0ddad7e1cb05",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# standard library modules\n",
                "import random                        # for sample\n",
                "import itertools                     # for count\n",
                "import sys                           # for stderr\n",
                "import math                          # for log\n",
                "\n",
                "# third-party modulees\n",
                "import ipywidgets                    # for interact\n",
                "from matplotlib import pyplot as plt # for plotting\n",
                "\n",
                "# course modules\n",
                "import clusterplot"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Toy dataset\n",
                "In this notebook we will use small toy dataset to explore how the K-means algorithm works.  This dataset consists of 100 2-dimensional profiles.  You can think of each of these profiles as a measurement of the RNA abundance of two genes.  Real gene expression profiles are typically of much higher dimension (on the order of thousands to tens of thousdands of dimensions, corresponding to number of genes in a genome), but for simplicity in understanding the K-means algorithm, we will consider just two dimensions.\n",
                "\n",
                "We will read this dataset from a file in the code below:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-eac1e44de666ac1f",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "sample_profiles_filename = \"sample_profiles.txt\"\n",
                "sample_profiles = [tuple(map(float, line.split())) for line in open(sample_profiles_filename)]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-7e5a9ff8daca88d0",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Here is a static visualization of this dataset:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-bcca51c42e8467e6",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "scrolled": false,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "clusterplot.plot_profiles(sample_profiles)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-49e3c7b6fba27b6b",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## The K-means algorithm\n",
                "In this activity we will implement the K-means clustering algorithm and visualize it in action.  Below is an implemention of the high-level aspects of the algorithm.  The high-level implementation is broken into two pieces:\n",
                "* `cluster_kmeans_iterator`: performs one run of the algorithm until termination, and provides an iterator over the results after each iteration.  This will be used for visualizing the algorithm later in this activity.\n",
                "* `cluster_kmeans`: a simple interface to the full algorithm. It runs through the the entire iterator provided by  `cluster_kmeans_iterator` and returns the final results. It can optionally run the algorithm multiple times with random initializations and return the best result.\n",
                "\n",
                "The pieces that are missing are the two main functions called within `cluster_kmeans_iterator`, which are:\n",
                "* `closest_center`: determines the closest cluster center to a given profile\n",
                "* `mean_profile`: computes the center of a cluster given the profiles assigned to it\n",
                "\n",
                "Take a look over the high-level functions and then provide implementations to these core functions in the first two problems."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def cluster_kmeans(profiles, k, initial_f=None, max_iterations=None, num_runs=1):\n",
                "    \"\"\"Runs the K-means algorithm, returning the final cluster assignments and centers.\n",
                "    \n",
                "    Args:\n",
                "        profiles: a list of profiles (vectors), with each profile represented as tuple\n",
                "        k: the number of clusters to find\n",
                "        initial_f: the initial cluster centers (optional)\n",
                "        max_iterations: the maximum number of iterations for the algorithm\n",
                "        num_runs: # of runs of the algorithm with random intializations\n",
                "    Returns:\n",
                "        A tuple (C, f), where C is a list with C[i] giving the index of the cluster to\n",
                "        which profile i is assigned, and f is a list of cluster centers (tuples) (e.g., f[j] \n",
                "        is the cluster center for cluster j).\n",
                "    \"\"\"\n",
                "    best_C, best_f, best_score = None, None, float(\"inf\")\n",
                "    for run in range(num_runs):\n",
                "        # iterate until termination\n",
                "        for C, f in cluster_kmeans_iterator(profiles, k, initial_f, max_iterations):\n",
                "            pass\n",
                "        score = within_cluster_scatter(profiles, C, f)\n",
                "        if score < best_score:\n",
                "            best_C, best_f, best_score = C, f, score\n",
                "\n",
                "    return best_C, best_f\n",
                "\n",
                "def cluster_kmeans_iterator(profiles, k, initial_f=None, max_iterations=None):\n",
                "    \"\"\"An iterator over the results the K-means algorithm after each of its iterations.\n",
                "    \n",
                "    The arguments and yielded values are the same as for cluster_kmeans.\n",
                "    \"\"\"\n",
                "    \n",
                "    # randomly select k of the input profiles as centers if initial_f not given\n",
                "    f = initial_f if initial_f else random.sample(profiles, k)\n",
                "    \n",
                "    # keep track of the last cluster assignments\n",
                "    last_C = None\n",
                "    \n",
                "    for iteration in itertools.count(1):\n",
                "        # stop if we have reached the maximum number of iterations\n",
                "        if max_iterations is not None and iteration > max_iterations:\n",
                "            print(\"Warning: max iterations reached\", file=sys.stderr)\n",
                "            break\n",
                "        \n",
                "        # (re)compute closest cluster for each profile\n",
                "        C = [closest_center(profile, f) for profile in profiles]\n",
                "        \n",
                "        # terminate if the cluster assignments do not change\n",
                "        if C == last_C: break\n",
                "\n",
                "        # (re)compute cluster centers\n",
                "        # create lists of profiles assigned to each cluster\n",
                "        clusters = group_by_cluster_assignment(profiles, C, k)\n",
                "        \n",
                "        # compute the means of each cluster\n",
                "        # if a cluster has no longer has points assigned to it, use its last center\n",
                "        f = [mean_profile(cluster) if cluster else f[i] for i, cluster in enumerate(clusters)]\n",
                "        \n",
                "        # yield the current results for possible inspection\n",
                "        yield C, f\n",
                "        \n",
                "        last_C = C\n",
                "\n",
                "def group_by_cluster_assignment(objects, assignments, k):\n",
                "    \"\"\"Returns a list of lists of the objects assigned to each cluster.\"\"\"\n",
                "    clusters = [[] for i in range(k)]\n",
                "    for obj, cluster_index in zip(objects, assignments):\n",
                "        clusters[cluster_index].append(obj)\n",
                "    return clusters\n",
                "\n",
                "def squared_euclidean_distance(p1, p2):\n",
                "    \"\"\"The square of the Euclidean distances between two profiles.\"\"\"\n",
                "    return sum((e1 - e2)**2 for e1, e2 in zip(p1, p2))\n",
                "\n",
                "def euclidean_distance(p1, p2):\n",
                "    \"\"\"The Euclidean distance between two profiles.\"\"\"\n",
                "    return math.sqrt(squared_euclidean_distance(p1, p2))\n",
                "\n",
                "def within_cluster_scatter(profiles, cluster_assignments, centers):\n",
                "    \"\"\"Computes the within-cluster scatter for a given clustering.\"\"\"\n",
                "    return sum(squared_euclidean_distance(p, centers[cluster_index])\n",
                "               for p, cluster_index in zip(profiles, cluster_assignments))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-8f7479c841fc2077",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## PROBLEM 1: Computing the closest cluster center to a profile (1 POINT)\n",
                "Implement the `closest_center` function, which determines the closest cluster center to a given profile.  Your function should use the `squared_euclidean_distance` function defined above."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def closest_center(profile, centers):\n",
                "    \"\"\"Returns the index of the cluster center that is closest to profile.\n",
                "    \n",
                "    If multiple centers are equally close, the smallest index is returned.\n",
                "    Args:\n",
                "        profile: a tuple representing the query profile\n",
                "        centers: a list of tuples representing the centers of each cluster.\n",
                "    Returns:\n",
                "        The index of the center that is closest (in Euclidean distance) to the query profile.\"\"\"\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "closest_center",
                    "locked": true,
                    "points": 1,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# tests for closest_center\n",
                "assert closest_center((2, 3), [(1, 6), (2, 8), (3, 4)]) == 2\n",
                "assert closest_center((2, 5), [(1, 6), (2, 8), (3, 4)]) == 0\n",
                "assert closest_center((2, 7), [(1, 6), (2, 8), (3, 4)]) == 1\n",
                "assert closest_center((2, 7), [(1, 6)]) == 0\n",
                "assert closest_center((3, 1, 2), [(4, 6, 1), (-2, 1, 2)]) == 1\n",
                "print(\"SUCCESS: all tests for closest_center passed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-0029bd8ce0ad57f7",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## PROBLEM 2: Computing the center of a cluster (1 POINT)\n",
                "Implement the `mean_profile` function, which determines the center (mean profile) of a single cluster of profiles."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def mean_profile(profiles):\n",
                "    \"\"\"Computes the center (mean) of a cluster of the given profiles.\n",
                "    \n",
                "    Args:\n",
                "        profiles: a list of profiles (tuples)\n",
                "    Returns:\n",
                "        a tuple representing the mean of the profiles.\"\"\"\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "mean_profile",
                    "locked": true,
                    "points": 1,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# tests for mean_profile\n",
                "assert mean_profile([(1, 6), (2, 8), (3, 4)]) == (2, 6)\n",
                "assert mean_profile([(1, 6), (3, 4)]) == (2, 5)\n",
                "assert mean_profile([(1, 6)]) == (1, 6)\n",
                "assert mean_profile([(3, 1, 2), (5, 7, 2), (-2, 1, 2)]) == (2, 3, 2)\n",
                "assert mean_profile([(3,), (5,), (-2,)]) == (2,)\n",
                "print(\"SUCCESS: all tests for mean_profile passed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-12048d27bb66b42f",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Visualization of the K-means algorithm\n",
                "\n",
                "Now that you have filled in the missing pieces of our K-means implementation, let's see the algorithm in action.  It will be helpful to visualize the state of the algorithm at each of its iterations.  Below is a function that we will use to visualize the progress of the K-means algorithm."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def plot_kmeans_iterations(profiles, k, initial_f=None):\n",
                "    \"\"\"Produce an interactive plot for visualizing the results of the K-means algorithm at each iteration.\"\"\"\n",
                "    iterations = list(cluster_kmeans_iterator(profiles, k, initial_f))\n",
                "    within_cluster_scatters = [within_cluster_scatter(profiles, C, f) for C, f in iterations]\n",
                "    def plot_iteration(iteration=0):\n",
                "        C, f = iterations[iteration]\n",
                "        scatter = round(within_cluster_scatters[iteration], 1)\n",
                "        title = \"Iteration={}, Within-cluster scatter={}\".format(iteration, scatter)\n",
                "        clusterplot.plot_profiles(profiles, C, f, title=title)\n",
                "        print(\"cluster centers:\", [tuple(round(x, 1) for x in center) for center in f])\n",
                "    ipywidgets.interact(plot_iteration, iteration=(0, len(iterations) - 1)) "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-6404e2b44907cf76",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "And here is an interactive plot of the result of running the K-means algorithm on our toy dataset, with $k = 5$.  Use the slider at the top of the plot to go through the iterations of the algorithm.  The value of the within-cluster scatter objective function is given at the top and the positions of the current cluster centers are printed at the bottom."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-6e5c7573b511f283",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "scrolled": false,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "plot_kmeans_iterations(sample_profiles, 5)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-4b263e1491593a26",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## PROBLEM 3: A \"good\" run of K-means (1 POINT)\n",
                "\n",
                "Recall that the K-means algorithm is sensistive to the initial positions of the cluster centers.  In this problem and the next, we will explore this issue by finding intial positions that result in \"good\" and \"bad \"clusterings.\n",
                "\n",
                "For $k = 5$, find a set of initial cluster centers that gives a \"good\" clustering for the sample points, where a \"good\" clustering has a within-cluster scatter score less than 100.  One approach here could be to run the `plot_kmeans_iterations` function multiple times (each call uses a different randomly selected set of intial cluster centers) until you find cluster centers that give a \"good\" clustering.\n",
                "\n",
                "Assign your list of cluster centers to the variable `good_cluster_centers` below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### good_cluster_centers=?\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "good_cluster_centers",
                    "locked": true,
                    "points": 1,
                    "schema_version": 1,
                    "solution": false
                },
                "scrolled": true,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# tests for good_cluster_centers\n",
                "assert len(good_cluster_centers) == 5\n",
                "cluster_assignments, centers = cluster_kmeans(sample_profiles, 5, good_cluster_centers)\n",
                "assert within_cluster_scatter(sample_profiles, cluster_assignments, centers) < 100\n",
                "print(\"SUCCESS: all tests for good_cluster_centers passed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-497f885ce71af1d0",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## PROBLEM 4: A \"bad\" run of K-means (1 POINT)\n",
                "For $k = 5$, find a set of initial cluster centers that gives a \"bad\" clustering for the sample points, where a \"bad\" clustering has a within-cluster scatter greater than 120.\n",
                "\n",
                "Assign your list of cluster centers to the variable bad_cluster_centers below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "###\n",
                "### bad_cluster_centers=?\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "bad_cluster_centers",
                    "locked": true,
                    "points": 1,
                    "schema_version": 1,
                    "solution": false
                },
                "scrolled": true,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# tests for bad_cluster_centers\n",
                "assert len(bad_cluster_centers) == 5\n",
                "cluster_assignments, centers = cluster_kmeans(sample_profiles, 5, bad_cluster_centers)\n",
                "assert within_cluster_scatter(sample_profiles, cluster_assignments, centers) > 120\n",
                "print(\"SUCCESS: all tests for bad_cluster_centers passed\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-11b9d271cd4ca69e",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Selecting the number of clusters (K)\n",
                "\n",
                "A common issue in flat clustering is how to select $K$, the number of clusters.  For K-means clustering one approach is to use a penalized objective function, with a penalty term that is a function of the number of clusters.  The general form of the penalized objective function for a clustering $C$ that has $K$ clusters is:\n",
                "\n",
                "$penalized\\_objective(C, K) = within\\_cluster\\_scatter(C) + \\lambda K$\n",
                "\n",
                "where $\\lambda$ is an user-set parameter.  Two statistically principed values for lambda are:\n",
                "\n",
                "* Akaike Information Criterion (AIC): $\\lambda = 2M$, where $M$ is the dimension of the profiles\n",
                "* Bayesian Information Criterion (BIC): $\\lambda = M\\log(N)$, where $M$ is the dimension of the profiles and $N$ is the number of profiles (the natural logarithm is used here)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-744121dd33ad6f48",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Let's explore clusterings of our toy dataset for a range of values of $K$ and see which one minimizes a penalized objective function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-e3590d28dd5ded76",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "k_values = range(1, 20)\n",
                "random.seed(2) # we will set the random seed so that everyone gets the same clustering for each value of k\n",
                "kmeans_clusterings = [cluster_kmeans(sample_profiles, k, num_runs=10) for k in k_values]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-c2021c9236c191d5",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We can view this set of clusterings with the `plot_multiple_kmeans_clusterings` function from the `clusterplot` module."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-3e22df37cd31bae6",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "clusterplot.plot_multiple_kmeans_clusterings(sample_profiles, kmeans_clusterings)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-915a5f27c2b9f956",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Below is a plot of the within-cluster scatter values for these clusterings.  Notice that the within-cluster scatter decreases as $K$ increases and thus that we cannot simply cannot use the within-cluster scatter as an objective function with which to select the best value of $K$."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-402c2ed771aa9ee7",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "scatters = [within_cluster_scatter(sample_profiles, *clustering) for clustering in kmeans_clusterings]\n",
                "plt.plot(k_values, scatters)\n",
                "plt.xlabel(\"K\")\n",
                "plt.ylabel(\"within cluster scatter\")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-381d94d245afb427",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## PROBLEM 5: AIC selected number of clusters (1 POINT)\n",
                "What value of $K$ would be selected by using the AIC penalized objective function?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "###\n",
                "### aic_k=?\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "aic_k",
                    "locked": true,
                    "points": 1,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# test for aic_k\n",
                "assert isinstance(aic_k, int)\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-b9c4a676f125c0db",
                    "locked": true,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## PROBLEM 6: BIC selected number of clusters (1 POINT)\n",
                "What value of $K$ would be selected by using the BIC penalized objective function?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "###\n",
                "### bic_k=?\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "bic_k",
                    "locked": true,
                    "points": 1,
                    "schema_version": 1,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# test for bic_k\n",
                "assert isinstance(bic_k, int)\n",
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        }
    ],
    "metadata": {
        "celltoolbar": "Create Assignment",
        "kernelspec": {
            "display_name": "Python 3 [3.6]",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}