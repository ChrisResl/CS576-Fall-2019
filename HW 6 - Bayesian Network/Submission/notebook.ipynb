{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-027da61e09ea6982",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# BMI/CS 576 - HW6\n",
    "The objectives of this homework are to better understand\n",
    "\n",
    "* the statistical dependencies represented by a Bayesian network\n",
    "* alternative representations of conditional probability distributions (CPDs)\n",
    "* how model evidence works as a score for Bayesian networks\n",
    "* the Sparse Candidate algorithm\n",
    "\n",
    "## HW policies\n",
    "Before starting this homework, please read over the [homework policies](https://canvas.wisc.edu/courses/167969/pages/hw-policies) for this course.  In particular, note that homeworks are to be completed *individually*.\n",
    "\n",
    "You are welcome to use any code from the weekly notebooks in your solutions to the HW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-51388c4a0f9b2aa3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PROBLEM 1 (30 POINTS)\n",
    "\n",
    "Consider the Bayesian network below \n",
    "\n",
    "![simple_network](simple_network.png)\n",
    "\n",
    "**(a)** Give a table specifying the joint probability distribution, $P(A, B, C)$ represented by the Bayesian network.\n",
    "\n",
    "**(b)** Given your table from (a), compute $P(A = true\\ |\\ C = true)$\n",
    "\n",
    "**(c)** Given your table from (a), compute $P(A = true\\ |\\ B = true)$\n",
    "\n",
    "**(d)** Given your table from (a), compute $P(A = true\\ |\\ B = true, C = true)$\n",
    "\n",
    "**(e)** Given your table from (a), is $A$ independent of $B$? Justify your answer.\n",
    "  \n",
    "**(f)** Given your table from (a), is $A$ independent of $B$ given $C$? Justify your answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p1",
     "locked": false,
     "points": 30,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "(a)\n",
    "\n",
    "| A | B | C | P |\n",
    "| - | - | - | - |\n",
    "| F | F | F | 0.3 |\n",
    "| F | F | T | 0 |\n",
    "| F | T | F | 0 |\n",
    "| F | T | T | 0.3 |\n",
    "| T | F | F | 0 |\n",
    "| T | F | T | 0.2 |\n",
    "| T | T | F | 0 |\n",
    "| T | T | T | 0.2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) \n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "& P(A = true\\ |\\ C = true) \\\\\n",
    "& = \\frac{P(A = true, C = true)}{P(C = true)} \\\\\n",
    "& = \\frac{0.2 + 0.2}{0.3 + 0.2 + 0.2} \\\\\n",
    "& = 0.571428571\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "& P(A = true\\ |\\ B = true) \\\\\n",
    "&= \\frac{P(A = true, B = true)}{P(B = true)} \\\\\n",
    "& = \\frac{0.2}{0.3 + 0.2} \\\\ \n",
    "& = 0.4\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d)\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "& P(A = true\\ |\\ B = true, C = true)  \\\\\n",
    "& = \\frac{P(A = true, B = true, C = true)}{P(B = true, C = true)} \\\\ \n",
    "& = \\frac{0.2}{0.3 + 0.2} \\\\\n",
    "& = 0.4\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e)\n",
    "\n",
    "$\n",
    "P(A = true) = 0.4 = P(A = true\\ |\\ B = true) \\\\\n",
    "P(A = true) = 0.4 = P(A = true\\ |\\ B = false) \\\\\n",
    "P(A = false) = 0.6 = P(A = false\\ |\\ B = true) \\\\\n",
    "P(A = false) = 0.6 = P(A = false\\ |\\ B = false) \\\\\n",
    "\\text{Therefore $A$ is independent of $B$}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f)\n",
    "\n",
    "$\n",
    "P(A = true\\ |\\ C = true) = 0.571428571 \\\\\n",
    "P(A = true\\ |\\ B = true, C = true)   = 0.4 \\\\\n",
    "\\text{Since $P(A = true\\ |\\ C = true) \\neq P(A = true\\ |\\ B = true, C = true)$, $A$ is not independent of $B$ given $C$}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3efc15f74bf1d298",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PROBLEM 2 (25 POINTS)\n",
    "As shown in the slide \"Representing CPDs for Discrete Variables\" (slide 8) of the lecture \"Networks - Introduction to Bayesian Networks\" some conditional probability distributions (CPD) can also be represented with a tree.\n",
    "\n",
    "**(a)** Give the CPD table for the distribution $P(D\\ |\\ A,B,C)$ represented by the tree below.\n",
    "![](decision_tree.png)\n",
    "\n",
    "**(b)** Give the most compact tree (i.e., one with the fewest nodes) represention of the distribution $P(D\\ |\\ A,B,C)$ specified by the CPD table below.\n",
    "\n",
    "![](decision_tree_cpd.png)\n",
    "\n",
    "**(c)** Suppose that you know that the CPD $P(D\\ |\\ A,B,C)$ can be represented by the tree structure of part (a), but that you don't know the parameters at the leaves of the tree.  Now suppose you are given some training data with which to estimate the CPD.  What is the major advantage of the tree representation over the CPD table representation in estimating the parameters of the CPD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)\n",
    "\n",
    "| A | B | C |  T  |  F  | \n",
    "| - | - | - |  -  |  -  | \n",
    "| F | F | F | 0.8 | 0.2 |\n",
    "| F | F | T | 0.8 | 0.2 |\n",
    "| F | T | F | 0.7 | 0.3 |\n",
    "| F | T | T | 0.7 | 0.3 | \n",
    "| T | F | F | 0.4 | 0.6 |\n",
    "| T | F | T | 0.5 | 0.5 | \n",
    "| T | T | F | 0.4 | 0.6 |\n",
    "| T | T | T | 0.5 | 0.5 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)\n",
    "<pre>\n",
    "               B                        \n",
    "              / \\                     \n",
    "             /   \\ \n",
    "          F /     \\ T\n",
    "           /       \\\n",
    "          /         \\\n",
    "    P(D=T)=0.75      A\n",
    "                    / \\\n",
    "                   /   \\ \n",
    "                F /     \\ T\n",
    "                 /       \\\n",
    "                /         \\\n",
    "          P(D=T)=0.5       C\n",
    "                          / \\\n",
    "                         /   \\ \n",
    "                      F /     \\ T\n",
    "                       /       \\\n",
    "                      /         \\ \n",
    "              P(D=T)=0.25     P(D=T)=0.5\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)\n",
    "\n",
    "The tree representation gives dependency information about the random variables. \n",
    "\n",
    "From the graph, we can clearly see that if we can determine that the value for A is True, then the value for B is no longer revelent. Similarily, once we are sure that the vaule for A is False, then the value for C is not revelent to the probability of D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da60905e0e67952f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PROBLEM 3 (30 POINTS)\n",
    "\n",
    "Consider two possible Bayesian networks for two binary random variables, $X_1$ and $X_2$, shown below.\n",
    "\n",
    "![](two_var_networks.png)\n",
    "\n",
    "**(a)** Give the likelihood function, $P(D|G_0, \\theta)$, for network $G_0$ in terms of the count variables shown in the table above.\n",
    "\n",
    "**(b)** Give the likelihood function, $P(D|G_1, \\theta)$, for network $G_1$ in terms of the count variables shown in the table above.\n",
    "\n",
    "**(c)** Suppose that we estimate maximum likelihood values, $\\hat{\\theta}_{MLE}$, for the parameters of each of the two networks given a data set, $D$.  Show that $P(D|G_1, \\hat{\\theta}_{MLE}) \\geq P(D|G_0, \\hat{\\theta}_{MLE})$ for any data set, $D$, and thus that the likelihood is not a good way to score networks. *Hint: consider what happens when $\\theta_2 = \\theta_{20} = \\theta_{21}$.*\n",
    "\n",
    "**(d)** Derive the model evidence, $P(D|G_0)$ for the network $G_0$ in terms of the count variables shown in the table above.\n",
    "\n",
    "**(e)** Derive the model evidence, $P(D|G_1)$ for the network $G_1$ in terms of the count variables shown in the table above.\n",
    "\n",
    "**(f)** Consider the case in which $n = 20$ and $n_{0-} = n_{1-} = n_{-0} = n_{-1} = 10$ (i.e., each row and column of the data table sum to half of the total observations).  Compute the difference in the log model evidence between the two models, $\\log(P(D|G_1)) - \\log(P(D|G_0))$, over all possible values of $n_{00}$ (note that specifying $n_{00}$ specifies all other counts).  These values indicate for which data sets we would prefer $G_1$ over $G_0$, and vice versa.  Show your results as a plot of $\\log(P(D|G_1)) - \\log(P(D|G_0))$ vs. $n_{00}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p3",
     "locked": false,
     "points": 30,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "(a)\n",
    "\n",
    "$\n",
    "P(D|G_0, \\theta) = \\theta_1^{n_{0-}} (1-\\theta_1)^{n_{1-}} \\theta_2^{n_{-0}} (1-\\theta_2)^{n_{-1}}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(D|G_1, \\theta) \n",
    "& =\n",
    "[\\theta_1\\theta_{20}] ^ {n_{00}}\n",
    "[\\theta_1(1-\\theta_{20})] ^ {n_{01}}\n",
    "[(1-\\theta_1)\\theta_{21}] ^ {n_{10}}\n",
    "[(1-\\theta_1)(1-\\theta_{21})] ^ {n_{11}} \\\\ \n",
    "& = \n",
    "[\\theta_1 ^ {n_{00}} \n",
    "\\theta_{20} ^ {n_{00}}]\n",
    "[\\theta_1 ^ {n_{01}}\n",
    "(1-\\theta_{20}) ^ {n_{01}}]\n",
    "[(1-\\theta_1) ^ {n_{10}}\n",
    "\\theta_{21} ^ {n_{10}}]\n",
    "[(1-\\theta_1) ^ {n_{11}}\n",
    "(1-\\theta_{21}) ^ {n_{11}}] \\\\ \n",
    "& = \n",
    "[\\theta_1 ^ {n_{00}} \\theta_1 ^ {n_{01}}]\n",
    "[(1-\\theta_1) ^ {n_{10}} (1-\\theta_1) ^ {n_{11}}]\n",
    "\\theta_{20} ^ {n_{00}}\n",
    "(1-\\theta_{20}) ^ {n_{01}}\n",
    "\\theta_{21} ^ {n_{10}}\n",
    "(1-\\theta_{21}) ^ {n_{11}} \\\\ \n",
    "& = \n",
    "\\theta_1^{n_{0-}}\n",
    "(1-\\theta_1)^{n_{1-}}\n",
    "\\theta_{20} ^ {n_{00}}\n",
    "(1-\\theta_{20}) ^ {n_{01}}\n",
    "\\theta_{21} ^ {n_{10}}\n",
    "(1-\\theta_{21}) ^ {n_{11}}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)\n",
    "\n",
    "$\n",
    "\\text{For sake of contradiction, suppose $P(D|G_0, \\theta)> P(D|G_1, \\theta)$. Then} \\\\ \n",
    "$\n",
    "$$\n",
    "\\begin{align}\n",
    "P(D|G_0, \\theta) & > P(D|G_1, \\theta) \\\\\n",
    "\\theta_1^{n_{0-}}\n",
    "(1-\\theta_1)^{n_{1-}}\n",
    "\\theta_2^{n_{-0}}\n",
    "(1-\\theta_2)^{n_{-1}}\n",
    "& >\n",
    "\\theta_1^{n_{0-}}\n",
    "(1-\\theta_1)^{n_{1-}}\n",
    "\\theta_{20} ^ {n_{00}}\n",
    "(1-\\theta_{20}) ^ {n_{01}}\n",
    "\\theta_{21} ^ {n_{10}}\n",
    "(1-\\theta_{21}) ^ {n_{11}} \\\\ \n",
    "\\theta_2^{n_{-0}}\n",
    "(1-\\theta_2)^{n_{-1}}\n",
    "& >\n",
    "\\theta_{20} ^ {n_{00}}\n",
    "(1-\\theta_{20}) ^ {n_{01}}\n",
    "\\theta_{21} ^ {n_{10}}\n",
    "(1-\\theta_{21}) ^ {n_{11}} \\\\ \n",
    "\\theta_2^{n_{00}}\n",
    "\\theta_2^{n_{10}}\n",
    "(1-\\theta_2)^{n_{01}}\n",
    "(1-\\theta_2)^{n_{11}}\n",
    "& >\n",
    "\\theta_{20} ^ {n_{00}}\n",
    "\\theta_{21} ^ {n_{10}}\n",
    "(1-\\theta_{20}) ^ {n_{01}}\n",
    "(1-\\theta_{21}) ^ {n_{11}} \\\\ \n",
    "\\end{align} \\\\\n",
    "$$\n",
    "\n",
    "$\n",
    "\\text{If $P(D|G_0, \\theta)$ can be maximized at $\\theta_{2} = \\hat{\\theta}_{2}$ for some $\\hat{\\theta}_{2}$. } \n",
    "\\text{Setting $\\theta_{20} = \\theta_{21} = \\hat{\\theta}_{2}$ for $P(D|G_1, \\theta)$. Then} \\\\\n",
    "$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(D|G_1, \\theta)\n",
    "& = \n",
    "\\theta_1^{n_{0-}}\n",
    "(1-\\theta_1)^{n_{1-}}\n",
    "\\theta_{20} ^ {n_{00}}\n",
    "(1-\\theta_{20}) ^ {n_{01}}\n",
    "\\theta_{21} ^ {n_{10}}\n",
    "(1-\\theta_{21}) ^ {n_{11}} \\\\\n",
    "& = \n",
    "\\theta_1^{n_{0-}}\n",
    "(1-\\theta_1)^{n_{1-}}\n",
    "\\hat{\\theta}_{2} ^ {n_{00}}\n",
    "(1-\\hat{\\theta}_{2}) ^ {n_{01}}\n",
    "\\hat{\\theta}_{2} ^ {n_{10}}\n",
    "(1-\\hat{\\theta}_{2}) ^ {n_{11}}\\\\\n",
    "& = \\theta_1^{n_{0-}} (1-\\theta_1)^{n_{1-}} \\hat{\\theta}_{2}^{n_{-0}} (1-\\hat{\\theta}_{2})^{n_{-1}} \\\\\n",
    "& = P(D|G_0, \\theta) \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$\n",
    "\\text{So $P(D|G_1, \\theta)$ can achieve the value as $P(D|G_0, \\theta)$ with $\\theta_{20} = \\theta_{21} = \\hat{\\theta}_{2}$. } \\\\\n",
    "\\text{Therefore it is impossible that $P(D|G_0, \\hat{\\theta}_{MLE})> P(D|G_1, \\hat{\\theta}_{MLE})$. } \\\\\n",
    "\\text{Thus, $P(D|G_0, \\hat{\\theta}_{MLE}) \\leq P(D|G_1, \\hat{\\theta}_{MLE})$}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d)\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(D|G_0) & = \\int_{\\theta}{P(D|\\theta, G_0)P(\\theta)d\\theta} \\\\\n",
    "& = \\int_{\\theta_1}{\\theta_1^{n_{0-}} (1-\\theta_1)^{n_{1-}} d\\theta_1} \\cdot \n",
    "    \\int_{\\theta_2}{\\theta_2^{n_{-0}} (1-\\theta_2)^{n_{-1}} d\\theta_2} \\\\\n",
    "& = \\frac{\\Gamma(n_{0-} + 1)\\Gamma(n_{1-} + 1)}{\\Gamma(n_{0-} + n_{1-} + 2)} \\cdot\n",
    "    \\frac{\\Gamma(n_{-0} + 1)\\Gamma(n_{-1} + 1)}{\\Gamma(n_{-0} + n_{-1} + 2)} \\\\\n",
    "& = \\left[(n+1)\\binom{n}{n_{0-}}\\right]^{-1} \\left[(n+1)\\binom{n}{n_{-0}}\\right]^{-1}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e)\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "P(D|G_1) & = \\int_{\\theta}{P(D|\\theta, G_1)P(\\theta)d\\theta} \\\\\n",
    "& = \\int_{\\theta_1}{\\theta_1^{n_{0-}} (1-\\theta_1)^{n_{1-}} d\\theta_1} \\cdot \n",
    "    \\prod_{i\\in\\{0, 1\\}}{\n",
    "        \\int_{\\theta_{2i}}{\\theta_{2i}^{n_{i0}} (1-\\theta_{2i})^{n_{i1}}d\\theta_{2i}}\n",
    "    } \\\\\n",
    "& = \\int_{\\theta_1}{\\theta_1^{n_{0-}} (1-\\theta_1)^{n_{1-}} d\\theta_1} \\cdot \n",
    "    \\int_{\\theta_{20}}{\\theta_{20}^{n_{00}} (1-\\theta_{20})^{n_{01}}d\\theta_{20}}\\cdot \n",
    "    \\int_{\\theta_{21}}{\\theta_{21}^{n_{10}} (1-\\theta_{21})^{n_{11}}d\\theta_{21}} \\\\\n",
    "& = \\left[(n+1)\\binom{n}{n_{0-}}\\right]^{-1}\n",
    "    \\left[(n_{0-}+1)\\binom{n_{0-}}{n_{00}}\\right]^{-1}\n",
    "    \\left[(n_{1-}+1)\\binom{n_{1-}}{n_{10}}\\right]^{-1}\n",
    "\\end{align}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bbd76a9bb92522be",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fa433559aa2bf51d",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAADDBJREFUeJzt3WGonQUdx/Hfr93EpmHKDlabdkeINpKyDmVJUpvBSnG+kFJQVhQjyDIRYvVGX/qiIl+IMcwaJFosISmpZBoVxPBuCrpdQ1On17Z2IrLozZR+vbhHWJfdXc95nnOf3f++H5B7znOf+zz/B8d3z33Oc3acRACAle8tXQ8AAGgHQQeAIgg6ABRB0AGgCIIOAEUQdAAogqADQBEEHQCKIOgAUMTUcu5szZo1mZ6eXs5dAsCKt3fv3r8n6S213rIGfXp6WjMzM8u5SwBY8WwffDPrcckFAIog6ABQBEEHgCIIOgAUQdABoAiCDgBFEHQAKIKgA0ARy/rGoiamt/9qYtt+8Y4rJ7ZtACvHpDqzXI3hDB0AiiDoAFDEkkG3fa/tI7afPmbZObYfsf3s8OvZkx0TALCUN3OG/mNJmxcs2y5pd5ILJO0ePgcAdGjJoCf5vaR/LFi8RdLO4eOdkq5peS4AwIjGvYZ+bpJDw8eHJZ3b0jwAgDE1flE0SSRlse/b3mZ7xvbMYDBoujsAwCLGDfrfbL9LkoZfjyy2YpIdSfpJ+r3ekh+4AQAY07hBf0jS1uHjrZJ+0c44AIBxvZnbFu+X9CdJF9qes/0lSXdI+rTtZyVdMXwOAOjQkm/9T3L9It/a1PIsAIAGeKcoABRB0AGgCIIOAEUQdAAogqADQBEEHQCKIOgAUARBB4AiCDoAFEHQAaAIgg4ARRB0ACiCoANAEQQdAIog6ABQBEEHgCIIOgAUQdABoAiCDgBFEHQAKIKgA0ARBB0AiiDoAFAEQQeAIgg6ABRB0AGgCIIOAEU0CrrtW2zvt/207fttn97WYACA0YwddNtrJX1dUj/J+yWtknRdW4MBAEbT9JLLlKS32Z6StFrSX5uPBAAYx9hBT/KKpO9IeknSIUmvJvltW4MBAEbT5JLL2ZK2SFov6d2SzrB9w3HW22Z7xvbMYDAYf1IAwAk1ueRyhaQXkgySvCbpQUkfX7hSkh1J+kn6vV6vwe4AACfSJOgvSbrU9mrblrRJ0mw7YwEARtXkGvoeSbsk7ZP01HBbO1qaCwAwoqkmP5zkNkm3tTQLAKAB3ikKAEUQdAAogqADQBEEHQCKIOgAUARBB4AiCDoAFEHQAaAIgg4ARRB0ACiCoANAEQQdAIog6ABQBEEHgCIIOgAUQdABoAiCDgBFEHQAKIKgA0ARBB0AiiDoAFAEQQeAIgg6ABRB0AGgCIIOAEUQdAAogqADQBGNgm77HbZ32X7G9qztj7U1GABgNFMNf/5OSb9Ocq3t0yStbmEmAMAYxg667bMkXS7pC5KU5Kiko+2MBQAYVZNLLuslDST9yPYTtu+xfcbClWxvsz1je2YwGDTYHQDgRJoEfUrShyTdneQSSf+RtH3hSkl2JOkn6fd6vQa7AwCcSJOgz0maS7Jn+HyX5gMPAOjA2EFPcljSy7YvHC7aJOlAK1MBAEbW9C6Xr0m6b3iHy/OSvth8JADAOBoFPcmTkvotzXJyuf2sCW771cltGyjknY89OZHtHv7UByey3a7xTlEAKIKgA0ARBB0AiiDoAFAEQQeAIgg6ABRB0AGgCIIOAEUQdAAogqADQBEEHQCKIOgAUARBB4AiCDoAFEHQAaAIgg4ARRB0ACiCoANAEQQdAIog6ABQBEEHgCIIOgAUQdABoAiCDgBFEHQAKIKgA0ARBB0AimgcdNurbD9h+5dtDAQAGE8bZ+g3S5ptYTsAgAYaBd32OklXSrqnnXEAAONqeob+fUnflPTfxVawvc32jO2ZwWDQcHcAgMWMHXTbV0k6kmTvidZLsiNJP0m/1+uNuzsAwBKanKFfJulq2y9KekDSRts/aWUqAMDIxg56km8lWZdkWtJ1kh5NckNrkwEARsJ96ABQxFQbG0nyO0m/a2NbAIDxcIYOAEUQdAAogqADQBEEHQCKIOgAUARBB4AiCDoAFEHQAaAIgg4ARRB0ACiCoANAEQQdAIog6ABQBEEHgCIIOgAUQdABoIhWPuACzV288+KJbfuprU9NbNs4dex+9L0T2/amjX+Z2LZPJZyhA0ARBB0AiiDoAFAEQQeAIgg6ABRB0AGgCIIOAEUQdAAogqADQBFjB932ebYfs33A9n7bN7c5GABgNE3e+v+6pFuT7LP9dkl7bT+S5EBLswEARjD2GXqSQ0n2DR//W9KspLVtDQYAGE0r19BtT0u6RNKeNrYHABhd46DbPlPSzyV9I8m/jvP9bbZnbM8MBoOmuwMALKJR0G2/VfMxvy/Jg8dbJ8mOJP0k/V6v12R3AIATaHKXiyX9UNJsku+1NxIAYBxNztAvk3SjpI22nxz+99mW5gIAjGjs2xaT/FGSW5wFANAA7xQFgCIIOgAUQdABoAiCDgBFEHQAKIKgA0ARBB0AiiDoAFAEQQeAIgg6ABRB0AGgCIIOAEUQdAAogqADQBEEHQCKIOgAUMTYH3CBlW/2ovdNZLvve2Z2ItvF/7v99ttX5LYxOZyhA0ARBB0AiiDoAFAEQQeAIgg6ABRB0AGgCIIOAEUQdAAogqADQBEEHQCKaBR025tt/9n2c7a3tzUUAGB0Ywfd9ipJd0n6jKQNkq63vaGtwQAAo2lyhv4RSc8leT7JUUkPSNrSzlgAgFE1CfpaSS8f83xuuAwA0AEnGe8H7WslbU7y5eHzGyV9NMlNC9bbJmmbJJ1//vkfPnjwYLOJsWLd9ZVHJ7Ldr/5g43GXf/fzV01kf7f+9JfHXT63/Q8T2Z8krbvjExPbNk5+tvcm6S+1XpMz9FcknXfM83XDZf8nyY4k/ST9Xq/XYHcAgBNpEvTHJV1ge73t0yRdJ+mhdsYCAIxq7E8sSvK67Zsk/UbSKkn3Jtnf2mQAgJE0+gi6JA9LerilWQAADfCZolg2i714WQUvXKJrvPUfAIog6ABQBEEHgCIIOgAUQdABoAiCDgBFcNsiylrs31wBquIMHQCKIOgAUARBB4AiCDoAFEHQAaAIgg4ARRB0ACiCoANAEQQdAIpwkuXbmT2QdHAZdrVG0t+XYT9dqn6MHN/KV/0Yl/P43pOkt9RKyxr05WJ7Jkm/6zkmqfoxcnwrX/VjPBmPj0suAFAEQQeAIqoGfUfXAyyD6sfI8a181Y/xpDu+ktfQAeBUVPUMHQBOOeWCbnuz7T/bfs729q7naZPt82w/ZvuA7f22b+56pkmwvcr2E7ZLfkKF7XfY3mX7Gduztj/W9Uxtsn3L8M/n07bvt3161zM1Zfte20dsP33MsnNsP2L72eHXs7ucUSoWdNurJN0l6TOSNki63vaGbqdq1euSbk2yQdKlkr5a7PjecLOk2a6HmKA7Jf06yUWSPqBCx2p7raSvS+oneb+kVZKu63aqVvxY0uYFy7ZL2p3kAkm7h887VSrokj4i6bkkzyc5KukBSVs6nqk1SQ4l2Td8/G/Nh2Btt1O1y/Y6SVdKuqfrWSbB9lmSLpf0Q0lKcjTJP7udqnVTkt5me0rSakl/7XiexpL8XtI/FizeImnn8PFOSdcs61DHUS3oayW9fMzzORUL3htsT0u6RNKebidp3fclfVPSf7seZELWSxpI+tHwstI9ts/oeqi2JHlF0nckvSTpkKRXk/y226km5twkh4aPD0s6t8thpHpBPyXYPlPSzyV9I8m/up6nLbavknQkyd6uZ5mgKUkfknR3kksk/Ucnwa/qbRleR96i+b+43i3pDNs3dDvV5GX+dsHObxmsFvRXJJ13zPN1w2Vl2H6r5mN+X5IHu56nZZdJutr2i5q/XLbR9k+6Hal1c5Lmkrzxm9UuzQe+iiskvZBkkOQ1SQ9K+njHM03K32y/S5KGX490PE+5oD8u6QLb622fpvkXYx7qeKbW2Lbmr73OJvle1/O0Lcm3kqxLMq35/3ePJil1dpfksKSXbV84XLRJ0oEOR2rbS5Iutb16+Od1kwq96LvAQ5K2Dh9vlfSLDmeRNP/rXxlJXrd9k6TfaP7V9XuT7O94rDZdJulGSU/ZfnK47NtJHu5wJozua5LuG550PC/pix3P05oke2zvkrRP83dlPaGT8B2Vo7J9v6RPSlpje07SbZLukPQz21/S/L8i+7nuJpzHO0UBoIhql1wA4JRF0AGgCIIOAEUQdAAogqADQBEEHQCKIOgAUARBB4Ai/gcGCJo5jTFm5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 20\n",
    "\n",
    "for n00 in range(11):\n",
    "    n01 = n/2 - n00\n",
    "    n10 = n/2 - n00\n",
    "    n11 = n - n01 - n10 - n00\n",
    "    \n",
    "    def binom(n, k):\n",
    "        return math.factorial(n) // math.factorial(k) // math.factorial(n - k)\n",
    "    \n",
    "    def inv_binom(n, k):\n",
    "        return ((n + 1) * binom(n, k)) ** -1\n",
    "\n",
    "    \n",
    "    g0 = inv_binom(n, n00 + n01) * inv_binom(n, n10 + n11)\n",
    "    g1 = inv_binom(n, n00 + n01) * inv_binom(n00 + n01, n00) * inv_binom(n10 + n11, n10)\n",
    "    \n",
    "    plt.bar(n00, math.log(g1) - math.log(g0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a1c731f8cc90e83b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## PROBLEM 4 (15 POINTS) \n",
    "\n",
    "\n",
    "Suppose we wish to reconstruct the gene regulatory network for three genes, $X$, $Y$, and $Z$, using the Bayesian network approach and the “sparse candidate” algorithm. We are given data from 100 independent experiments in which the expression levels of the three genes are measured. For simplicity, we model each gene as being either “on” (T) or “off” (F). Below is a table summarizing the number of times (count) each configuration of gene expression status was observed in these experiments.\n",
    "\n",
    "\n",
    "| X | Y | Z | count |\n",
    "|---|---|---|-------|\n",
    "| T | T | T |  36   |\n",
    "| T | T | F |   4   |\n",
    "| T | F | T |   2   |\n",
    "| T | F | F |   8   |\n",
    "| F | T | T |   9   |\n",
    "| F | T | F |   1   |\n",
    "| F | F | T |   8   |\n",
    "| F | F | F |  32   |\n",
    "\n",
    "\n",
    "**(a)** Suppose we wish to compute a single candidate parent for $Z$. In the first round of the “sparse candidate” algorithm, we compute the mutual information between $Z$ and the other random variables. Compute the mutual information between $Z$ and $X$, $I(X,Z)$, based on the frequencies observed in the data.\n",
    "\n",
    "**(b)** Compute the mutual information between $Z$ and $Y$, $I(Y,Z)$, based on the frequencies observed in the data.\n",
    "\n",
    "**(c)** Based on your answers to (a) and (b), which gene would be selected as the candidate parent for Z? Briefly explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "p4",
     "locked": false,
     "points": 15,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "(a)\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "I(X, Z) \n",
    "& =\n",
    "\\hat{P}(X=T, Z=T)\\log{\\frac{\\hat{P}(X=T, Z=T)}{\\hat{P}(X=T)\\hat{P}(Z=T)}} \\\\\n",
    "& \\quad + \\hat{P}(X=T, Z=F)\\log{\\frac{\\hat{P}(X=T, Z=F)}{\\hat{P}(X=T)\\hat{P}(Z=F)}} \\\\\n",
    "& \\quad + \\hat{P}(X=F, Z=T)\\log{\\frac{\\hat{P}(X=F, Z=T)}{\\hat{P}(X=F)\\hat{P}(Z=T)}} \\\\\n",
    "& \\quad + \\hat{P}(X=F, Z=F)\\log{\\frac{\\hat{P}(X=F, Z=F)}{\\hat{P}(X=F)\\hat{P}(Z=F)}} \\\\\n",
    "& = \n",
    "0.38 \\log{\\frac{0.38}{0.5\\cdot0.55}} + \n",
    "0.12 \\log{\\frac{0.12}{0.5\\cdot0.45}} + \n",
    "0.17 \\log{\\frac{0.17}{0.5\\cdot0.55}} + \n",
    "0.33 \\log{\\frac{0.33}{0.5\\cdot0.45}} \\\\\n",
    "& = 0.0920811\n",
    "\\end{align}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(b)\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "I(Y, Z) \n",
    "& =\n",
    "\\hat{P}(Y=T, Z=T)\\log{\\frac{\\hat{P}(Y=T, Z=T)}{\\hat{P}(Y=T)\\hat{P}(Z=T)}} \\\\\n",
    "& \\quad + \\hat{P}(Y=T, Z=F)\\log{\\frac{\\hat{P}(Y=T, Z=F)}{\\hat{P}(Y=T)\\hat{P}(Z=F)}} \\\\\n",
    "& \\quad + \\hat{P}(Y=F, Z=T)\\log{\\frac{\\hat{P}(Y=F, Z=T)}{\\hat{P}(Y=F)\\hat{P}(Z=T)}} \\\\\n",
    "& \\quad + \\hat{P}(Y=F, Z=F)\\log{\\frac{\\hat{P}(Y=F, Z=F)}{\\hat{P}(Y=F)\\hat{P}(Z=F)}} \\\\\n",
    "& = \n",
    "0.45 \\log{\\frac{0.45}{0.5\\cdot0.55}} + \n",
    "0.05 \\log{\\frac{0.05}{0.5\\cdot0.45}} + \n",
    "0.1 \\log{\\frac{0.1}{0.5\\cdot0.55}} + \n",
    "0.4 \\log{\\frac{0.4}{0.5\\cdot0.45}} \\\\\n",
    "& = 0.275396\n",
    "\\end{align}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)\n",
    "\n",
    "Since $I(Y, Z)$ > $I(X, Z)$, Y would be selected as the candidate parent for Z. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
